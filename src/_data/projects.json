[
  { 
    "title": "Machine Learning",
    "description": "Movie Recommendation and Review Analysis",
    "image": "/projectImages/Movie_recommedation.png",
    "image2": "/projectImages/movies.jpeg",
    "image3": "/projectImages/planner3.png",
    "technologies": ["API", "ETL processing","Flask", "Data Collecting", "Databases"],
    "body": "This project implements a robust movie recommendation system with sentiment analysis using MLops concepts. The system collects movie data including information about the cast, crew, and reviews using APIs then clean the data and train the model. \n It utilizes the TMDb API for fetching movies data. The recommendation system is based on cosine similarity, providing accurate recommendations even for movies not present in the dataset When movie is not present in the dataset it will collect the relevent information through API and store the information in Database then calcuate the cosine metrix again and give the results on the basis of new movie \n In addition to providing recommendations, the system also conducts sentiment analysis on each review. Reviews with a negative sentiment are displayed in red, while reviews with a positive sentiment are displayed in green, along with the recommended movie information.",
    "github": "https://github.com/ChanderMohan27/Movie_Recommendation_And_Review_Analysis/",
    "_deployed": "https://chandermohan27-whatapp-chat-analyzer-app-ygtqge.streamlit.app/",
    "bgcolor": "#9BA0E8",
    "id": "8"
  },
  { 
    "title": "Data Analysis",
    "description": "Whatapp Chat Analysis",
    "image": "/projectImages/chatt.png",
    "image2": "/projectImages/whatappp.png",
    "image3": "/projectImages/planner3.png",
    "technologies": ["Seaborn", "Python","Streamlit", "Numpy", "Pandas", "Matplotlib"],
    "body": "The WhatsApp Chat Analyzer is a Streamlit-based web application designed to analyze and visualize WhatsApp chat data. \n Users can upload chat transcripts in text format, initiating a preprocessing step to extract essential information such as timestamps, sender names, and message content. Once cleaned and transformed, the data undergoes comprehensive analysis, enabling users to gain insights into various aspects of the conversation. \n From timeline analysis, highlighting monthly and daily trends in message frequency, to user activity analysis, identifying the most active participants, the application offers a wide range of analytical features. Moreover, word frequency analysis and wordcloud generation provide visual representations of common words and phrases used in the chat, offering valuable insights into communication patterns. \n Through an interactive interface, users can dynamically explore different analysis options, customize parameters, and visualize results using line charts, heatmaps, pie charts, and bar graphs. Ultimately, the WhatsApp Chat Analyzer serves as a powerful tool for uncovering trends, patterns, and valuable insights within WhatsApp conversations, facilitating deeper understanding and analysis of communication dynamics.",
    "github": "https://github.com/ChanderMohan27/Whatapp-Chat-analyzer",
    "deployed": "https://chandermohan27-whatapp-chat-analyzer-app-ygtqge.streamlit.app/",
    "bgcolor": "#4BFFB6",
    "id": "7"
  },
  { 
    "title": "Emotion Recognition",
    "description": "Facial Emotion Prediction",
    "image": "/projectImages/Emotion_image.png",
    "image2": "/projectImages/facial1.png",
    "image3": "/projectImages/facial1.png",
    "body": "The objective of this project is to develop a single CNN neural network that will automatically recognize facial expression and facs code for an image. I also develop my own data loader to preprocess the images and make them suitable for modelling. In this project, I have used CK+ dataset consisting of 560 labelled images from 123 subjects. The dataset contains different types of images like grayscale and RGB images.\n In this project, I have implemented my knowledge by experimenting with different model and at the end I have selected VGG16 Model by using transfer learning. I also utalize image preprocessing, Transfer Learning, experiments and tuning, Adam Learning Rate and other regularization techniques. I am using a small dataset so making a good model with small data in a neural network is challenging for me so I have also used data augmentation techniques to reduce the overfitting of the model.\n This dataset is imbalance, so for emotion prediction and decision making, I used accuracy for emotion prediction and F1 score for facs units prediction with a threshold 0.5  to make the decision at the end." ,
    "technologies": ["Tensorfolw", "Keras API", "Data Augmentation", "Plotly", "VGG16 Model"],
    "github": "https://github.com/ChanderMohan27/Deep-Learning-CNN-",
    "_deployed": "https://norrinradd8.github.io/bike_buddy/",
    "bgcolor": "var(--hl2-color)",
    "id": "1"
  },
  {
    "title": "Credit Risk",
    "description": "Credit Risk Prediction",
    "image": "/projectImages/credit_risk_2.png",
    "image2": "/projectImages/Credit_risk.jpg",
    "image3": "/projectImages/Credit_risk.png",
    "technologies": ["Data Analysis", "Model Development", "Flask", "Financial Modeling","Team Collaboration"],
    "body": "During my masters, I collaborated with a team to develop a credit risk management system â€“ A machine learning model that will automate the decision-making process in the financial domain. Demonstrating a comprehensive understanding of the project's intricacies, I  took charge of the entire preprocessing of the data and Machine Learning Model Implementation.\n The purpose of this project is to use efficient machine learning models to automate the decision-making process that will be complimentary for both consumers and the institutions. Also, it is required to make the ML models explainable to reduce frauds in the finance industry, biases like illegal discrimination and promote transparency as most of the ML models are highly complex and complicated to interpret for consumers.\n For user interface we have used Flask framework to create a user interface where they can enter the details required for calculating the loan approval decision and then the approval decision appears on the same screen with a reason for that particular outcome.",
    "github": "https://github.com/ChanderMohan27/Credit-Risk-Management-Data-Science-Project",
    "_deployed": "",
    "bgcolor": "var(--hl-color)",
    "id": "2"
  },
  {
    "title": "Predictive Modeling",
    "description": "Cirrhosis Disease Prediction",
    "image": "/projectImages/Predictive_modeling.png",
    "image2": "/projectImages/disease.jpeg",
    "image3": "/projectImages/disease.png",
    "technologies": ["Data Preprocessing","Data Analysis", "Feature Engineering", "Model Selection", "Hyperparameter tuning"],
    "body": "This project is about cirrhosis disease prediction like a person has which stage of cirrhosis disease. The dataset for this project is taken from kaggle. The project's well-organized methodology and structure, which includes data preprocessing, feature selection, model fitting, hyperparameter tuning, and model comparison, are its strongest points.\n During data preprocessing, various cleaning techniques were applied to ensure the dataset's quality. There are a number of features in the dataset so I have used random forest feature selection to get top 10 features. The models that I have used for experiments are KNN, decision tree, random forest, and naive Bayes. I utilized CVGrid Search for hyperparameter tuning and experimenting with various parameters. \n To compare the performance of the different models, classification reports were generated, providing insights into accuracy, precision, recall, and F1-score for each model. Furthermore, to determine if there were any significant differences in accuracy between models, a t-test was conducted.",
    "github": "https://github.com/ChanderMohan27/Machine-Learning-Project-Predictive-Modeling-",
    "_deployed": "",
    "bgcolor": "#6c4bf4",
    "id": "3"
  },
  {
    "title": "Netural Language Processing",
    "description": "Job Advertisement Classifcation",
    "image": "/projectImages/nlp_main.png",
    "image2": "/projectImages/Nlp.jpeg",
    "image3": "/projectImages/Nlp.png",
    "technologies": ["NLTK","Text Preprocessing","Vector Feature Extraction", "Big Data Processing","Flask", "HTML"],
    "body": "This project is about classifying the category of a given job description. The Data is stored in multiple files and folders in xml format and with unknown data quality issues. I integrate the given data set with another data source, identify and resolve conflicts in data integration. I used appropriate Python tools and libraries to parse the data into a pandas dataframe.\n To construct an effective machine learning model, I performed text preprocessing on the dataset. This involved generating feature representations for job advertisement descriptions utilizing TF-IDF. Subsequently, I developed machine learning models specifically for document classification and carried out a thorough evaluation and analysis of these models.\n To make this project user interface, I used Flask framework in user can file a job and search for a specific Job. I have also added a feature that users can provide the Job description so the machine learning model will classify the Job category.",
    "github": "https://github.com/ChanderMohan27/NLP-Project",
    "_deployed": "",
    "bgcolor": "#f85781",
    "id": "4"
  },

  {
    "title": "Data Visualization",
    "description": "Crime in India",
    "image": "/projectImages/data_v_1.png",
    "image2": "/projectImages/data_visualization.jpg",
    "image3": "/projectImages/p13.png",
    "body": "Crime in India is a pressing concern that demands thorough analysis and understanding. This data visualization project aims to conduct a State-wise Crime Analysis for the Year 2017. By utilizing R programming for data visualization, we intend to provide a comprehensive overview of crime statistics across different states in India, uncovering valuable insights from the data.\n The primary objective of this analysis is to explore and visualize the patterns and prevalence of crime in India. Additionally, we seek to understand the potential factors influencing crime rates by comparing them with the unemployment rate and other relevant factors. The insights derived from this analysis can contribute to a better understanding of the issue and facilitate the formulation of effective strategies for crime prevention.\n Using R programming and relevant packages for geospatial data visualization, we will create interactive maps and graphs to represent crime statistics across different states.",
    "technologies": ["R Programming","Data Analysis", "ggplot2", "Data Preprocessing", "dplyr", "tidyr"],
    "github": "https://github.com/ChanderMohan27/Data-Visualization-Using-R",
    "Rpubs": "https://rpubs.com/Chander26/1051342",
    "bgcolor": "#e47911",
    "id": "5"
  },

  {
    "title": "MLops",
    "description": "Migraine Analysis",
    "image": "/projectImages/cd.png",
    "image2": "/projectImages/ML2.jpg",
    "image3": "/projectImages/planner3.png",
    "technologies": ["DVC", "MLops Pipelines","ML Flow", "CI-CD", "Random Forest", "Cookiecutter"],
    "body": "In this machine learning project, the primary focus is on establishing a robust MLOps pipeline, integrating it with a CI/CD pipeline, and leveraging the Data Version Control (DVC) framework. The goal is to streamline and automate the end-to-end machine learning lifecycle.\n To develop this model using a CI/CD pipeline, we utilized Cookiecutter to establish the project structure. For Data Version Control, the DVC framework along with dvc-gdrive was employed. After structuring the project, we implemented a dvc.yaml file, segregating the code into distinct modules like load_data.py, Data_preprocessing.py, and train_model.py. The chosen model is a Random Forest, suitable for this classification problem given the imbalanced nature of the data. To address the imbalance, we aggregated some target values. Additionally, feature engineering was applied to identify and utilize the top 10 relevant features.\n We utilize JSON files to automatically store important results from our model evaluation. The F1 score is a measure of a model's accuracy that considers both precision and recall. ",
    "github": "https://github.com/ChanderMohan27/Migraine_Analysis_Machine_Learnnig",
    "_deployed": "",
    "bgcolor": "#3e67ff",
    "id": "6"
  }
  

]
